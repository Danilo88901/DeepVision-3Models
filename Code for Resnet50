# Imports and environment setup
# ========================================
import os
import pandas as pd
from PIL import Image
import torch
from torch import nn
import torch.nn.functional as F
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as transforms
from torchvision import models
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt

# ========================================
# 1. Custom Dataset for Cassava
# ========================================
class CassavaDataset(Dataset):
    """
    Custom Dataset for Cassava Leaf Disease Classification.
    Expects a CSV with columns [filename, label], and root directory for images.
    """
    def __init__(self, csv_file: str, root_dir: str, transform=None):
        self.annotations = pd.read_csv(csv_file)  # DataFrame with columns: filename, label
        self.root_dir = root_dir                  # Path to image folder
        self.transform = transform                # torchvision transforms

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, idx):
        # Get image path and label
        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])
        image = Image.open(img_name).convert("RGB")
        label = int(self.annotations.iloc[idx, 1])

        if self.transform:
            image = self.transform(image)
        return image, label

# ========================================
# 2. Prepare transforms and DataLoaders
# ========================================
# Paths (adjust to your setup)
csv_train = '/content/cassava_data/train.csv'
img_dir = '/content/cassava_data/train_images'

# Train transforms: augmentations + resize + tensor + normalize
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# Validation transforms: only resize + tensor + normalize
val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225]),
])

# Create full dataset with train transforms
full_dataset = CassavaDataset(csv_file=csv_train, root_dir=img_dir, transform=train_transform)

# Split into train/validation (90% / 10%)
train_size = int(0.9 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_subset, val_subset = random_split(full_dataset, [train_size, val_size])

# Wrap validation subset to apply val_transform instead of train_transform
class WrappedSubset(Dataset):
    """
    Wraps a Subset to apply a different transform (e.g., validation transforms).
    """
    def __init__(self, subset, base_dataset: CassavaDataset, transform):
        self.subset = subset
        self.base_dataset = base_dataset
        self.transform = transform

    def __len__(self):
        return len(self.subset)

    def __getitem__(self, idx):
        orig_idx = self.subset.indices[idx]
        img_name = self.base_dataset.annotations.iloc[orig_idx, 0]
        label = int(self.base_dataset.annotations.iloc[orig_idx, 1])
        img_path = os.path.join(self.base_dataset.root_dir, img_name)
        image = Image.open(img_path).convert("RGB")
        image = self.transform(image)
        return image, label

train_dataset = train_subset  # uses train_transform via full_dataset
val_dataset = WrappedSubset(val_subset, full_dataset, val_transform)

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch_size = 40

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,
                          num_workers=4, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,
                        num_workers=4, pin_memory=True)

print(f"Device: {device}, Train size: {len(train_dataset)}, Val size: {len(val_dataset)}")

# ========================================
# 3. Compute class weights if needed
# ========================================
# Example: compute from train_dataset labels to handle imbalance
train_labels = []
for _, label in train_dataset:
    train_labels.append(label)
label_series = pd.Series(train_labels)
class_counts = label_series.value_counts().sort_index().values.astype(float)
class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)
class_weights = class_weights / class_weights.sum() * len(class_counts)
class_weights = class_weights.to(device)
print(f"Class counts: {class_counts}, Class weights: {class_weights}")

# ========================================
# 4. Freeze function for transfer learning
# ========================================
def set_parameter_requires_grad(model, freeze_ratio=0.8):
    """
    Freeze the first freeze_ratio portion of parameters, unfreeze the remaining.
    Args:
        model: nn.Module
        freeze_ratio: float in [0,1], fraction of total parameters to freeze
    """
    params = list(model.parameters())
    total = len(params)
    freeze_up_to = int(total * freeze_ratio)
    for i, param in enumerate(params):
        param.requires_grad = False if i < freeze_up_to else True
    print(f"Froze {freeze_up_to}/{total} parameter tensors; unfroze {total - freeze_up_to}.")

# ========================================
# 5. Initialize ResNet50, modify head, freeze layers
# ========================================
model = models.resnet50(pretrained=True)
num_classes = 5
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Move model to device before freezing (not strictly required, but consistent)
model = model.to(device)
set_parameter_requires_grad(model, freeze_ratio=0.8)

# ========================================
# 6. Loss, optimizer, scheduler
# ========================================
loss_fn = nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),
                              lr=4e-5, weight_decay=0.001)
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# ========================================
# 7. Training and validation loop
# ========================================
epochs = 12
best_val_f1 = 0.0

# Lists to store metrics per epoch
train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []
train_f1s, val_f1s = [], []

for epoch in range(1, epochs + 1):
    # --- Training phase ---
    model.train()
    running_loss = 0.0
    all_labels, all_preds = [], []

    for batch_idx, (images, labels) in enumerate(train_loader):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = loss_fn(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        preds = outputs.softmax(dim=1).argmax(dim=1)
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())

        if batch_idx % 300 == 0:
            seen = batch_idx * images.size(0)
            total = len(train_loader.dataset)
            print(f"Epoch {epoch}, processed {seen}/{total} samples")

    train_loss = running_loss / len(train_loader)
    train_acc = accuracy_score(all_labels, all_preds)
    train_f1 = f1_score(all_labels, all_preds, average='macro')

    # --- Validation phase ---
    model.eval()
    val_running_loss = 0.0
    val_labels, val_preds = [], []

    with torch.inference_mode():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = loss_fn(outputs, labels)
            val_running_loss += loss.item()

            preds = outputs.softmax(dim=1).argmax(dim=1)
            val_labels.extend(labels.cpu().numpy())
            val_preds.extend(preds.cpu().numpy())

    val_loss = val_running_loss / len(val_loader)
    val_acc = accuracy_score(val_labels, val_preds)
    val_f1 = f1_score(val_labels, val_preds, average='macro')

    print(f"Epoch {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f} "
          f"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}")

    # Save best model
    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save(model.state_dict(), "best_model.pth")
        print("âœ… Best model updated!")

    # Step scheduler
    scheduler.step()

    # Record metrics
    train_losses.append(train_loss)
    val_losses.append(val_loss)
    train_accuracies.append(train_acc)
    val_accuracies.append(val_acc)
    train_f1s.append(train_f1)
    val_f1s.append(val_f1)

# ========================================
# 8. Plot metrics
# ========================================
epochs_range = range(1, epochs + 1)
plt.figure(figsize=(18, 5))

# Loss plot
plt.subplot(1, 3, 1)
plt.plot(epochs_range, train_losses, label='Train Loss', marker='o')
plt.plot(epochs_range, val_losses, label='Val Loss', marker='o')
plt.title('Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# Accuracy plot
plt.subplot(1, 3, 2)
plt.plot(epochs_range, train_accuracies, label='Train Acc', marker='o')
plt.plot(epochs_range, val_accuracies, label='Val Acc', marker='o')
plt.title('Accuracy per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# F1 Score plot
plt.subplot(1, 3, 3)
plt.plot(epochs_range, train_f1s, label='Train F1', marker='o')
plt.plot(epochs_range, val_f1s, label='Val F1', marker='o')
plt.title('F1 Score per Epoch')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()
